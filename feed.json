{
    "version": "https://jsonfeed.org/version/1",
    "title": "个人首页",
    "subtitle": "欢迎来到智慧笔记~这里主要会记录编程学习笔记🌸",
    "icon": "http://127.0.0.1/images/favicon.ico",
    "description": "anoxia的后端博客",
    "home_page_url": "http://127.0.0.1",
    "items": [
        {
            "id": "http://127.0.0.1/blog-redis/Redis%E9%9D%A2%E8%AF%95%E9%A2%98-%E5%8F%82%E8%80%83%E5%9B%9E%E7%AD%94/",
            "url": "http://127.0.0.1/blog-redis/Redis%E9%9D%A2%E8%AF%95%E9%A2%98-%E5%8F%82%E8%80%83%E5%9B%9E%E7%AD%94/",
            "title": "Redis相关面试题",
            "date_published": "2023-08-05T16:00:00.000Z",
            "content_html": "<blockquote>\n<p><strong>面试官</strong>：什么是缓存穿透？怎么解决？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯～～，我想一下</p>\n<p>缓存穿透是指查询一个一定<strong>不存在</strong>的数据，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，可能导致 DB 挂掉。这种情况大概率是遭到了攻击。</p>\n<p>解决方案的话，我们通常都会用布隆过滤器来解决它</p>\n<p><strong>面试官</strong>：好的，你能介绍一下布隆过滤器吗？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯，是这样～</p>\n<p>布隆过滤器主要是用于检索一个元素是否在一个集合中。我们当时使用的是 redisson 实现的布隆过滤器。</p>\n<p>它的底层主要是先去初始化一个比较大数组，里面存放的二进制 0 或 1。在一开始都是 0，当一个 key 来了之后经过 3 次 hash 计算，模于数组长度找到数据的下标然后把数组中原来的 0 改为 1，这样的话，三个数组的位置就能标明一个 key 的存在。查找的过程也是一样的。</p>\n<p>当然是有缺点的，布隆过滤器有可能会产生一定的误判，我们一般可以设置这个误判率，大概不会超过 5%，其实这个误判是必然存在的，要不就得增加数组的长度，其实已经算是很划分了，5% 以内的误判率一般的项目也能接受，不至于高并发下压倒数据库。</p>\n<p><strong>面试官</strong>：什么是缓存击穿？怎么解决？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯！！</p>\n<p>缓存击穿的意思是对于设置了过期时间的 key，缓存在某个时间点过期的时候，恰好这时间点对这个 Key 有大量的并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把 DB 压垮。</p>\n<p>解决方案有两种方式：</p>\n<p>第一可以使用互斥锁：当缓存失效时，不立即去 load db，先使用如 Redis 的 setnx 去设置一个互斥锁，当操作成功返回时再进行 load db 的操作并回设缓存，否则重试 get 缓存的方法</p>\n<p>第二种方案可以设置当前 key 逻辑过期，大概是思路如下：</p>\n<p>①：在设置 key 的时候，设置一个过期时间字段一块存入缓存中，不给当前 key 设置过期时间</p>\n<p>②：当查询的时候，从 redis 取出数据后判断时间是否过期</p>\n<p>③：如果过期则开通另外一个线程进行数据同步，当前线程正常返回数据，这个数据不是最新</p>\n<p>当然两种方案各有利弊：</p>\n<p>如果选择数据的强一致性，建议使用分布式锁的方案，性能上可能没那么高，锁需要等，也有可能产生死锁的问题</p>\n<p>如果选择 key 的逻辑删除，则优先考虑的高可用性，性能比较高，但是数据同步这块做不到强一致。</p>\n<p><strong>面试官</strong>：什么是缓存雪崩？怎么解决？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯！！</p>\n<p>缓存雪崩意思是设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB，DB 瞬时压力过重雪崩。与缓存击穿的区别：雪崩是很多 key，击穿是某一个 key 缓存。</p>\n<p>解决方案主要是可以将缓存失效时间分散开，比如可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p>\n<p><strong>面试官</strong>：redis 做为缓存，mysql 的数据如何与 redis 进行同步呢？（双写一致性）</p>\n<p><strong>候选人</strong>：嗯！就说我最近做的这个项目，里面有 xxxx（<strong>根据自己的简历上写</strong>）的功能，需要让数据库与 redis 高度保持一致，因为要求时效性比较高，我们当时采用的读写锁保证的强一致性。</p>\n<p>我们采用的是 redisson 实现的读写锁，在读的时候添加共享锁，可以保证读读不互斥，读写互斥。当我们更新数据的时候，添加排他锁，它是读写，读读都互斥，这样就能保证在写数据的同时是不会让其他线程读数据的，避免了脏数据。这里面需要注意的是读方法和写方法上需要使用同一把锁才行。</p>\n<p><strong>面试官</strong>：那这个排他锁是如何保证读写、读读互斥的呢？</p>\n<p><strong>候选人</strong>：其实排他锁底层使用也是 setnx，保证了同时只能有一个线程操作锁住的方法</p>\n<p><strong>面试官</strong>：你听说过延时双删吗？为什么不用它呢？</p>\n<p><strong>候选人</strong>：延迟双删，如果是写操作，我们先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据，其中这个延时多久不太好确定，在延时的过程中可能会出现脏数据，并不能保证强一致性，所以没有采用它。</p>\n<p><strong>面试官</strong>：redis 做为缓存，mysql 的数据如何与 redis 进行同步呢？（双写一致性）</p>\n<p><strong>候选人</strong>：嗯！就说我最近做的这个项目，里面有 xxxx（<strong>根据自己的简历上写</strong>）的功能，数据同步可以有一定的延时（符合大部分业务）</p>\n<p>我们当时采用的阿里的 canal 组件实现数据同步：不需要更改业务代码，部署一个 canal 服务。canal 服务把自己伪装成 mysql 的一个从节点，当 mysql 数据更新以后，canal 会读取 binlog 数据，然后在通过 canal 的客户端获取到数据，更新缓存即可。</p>\n<p><strong>面试官</strong>：redis 做为缓存，数据的持久化是怎么做的？</p>\n<p><strong>候选人</strong>：在 Redis 中提供了两种数据持久化的方式：1、RDB  2、AOF</p>\n<p><strong>面试官</strong>：这两种持久化方式有什么区别呢？</p>\n<p><strong>候选人</strong>：RDB 是一个快照文件，它是把 redis 内存存储的数据写到磁盘上，当 redis 实例宕机恢复数据的时候，方便从 RDB 的快照文件中恢复数据。</p>\n<p>AOF 的含义是追加文件，当 redis 操作写命令的时候，都会存储这个文件中，当 redis 实例宕机恢复数据的时候，会从这个文件中再次执行一遍命令来恢复数据</p>\n<p><strong>面试官</strong>：这两种方式，哪种恢复的比较快呢？</p>\n<p><strong>候选人</strong>：RDB 因为是二进制文件，在保存的时候体积也是比较小的，它恢复的比较快，但是它有可能会丢数据，我们通常在项目中也会使用 AOF 来恢复数据，虽然 AOF 恢复的速度慢一些，但是它丢数据的风险要小很多，在 AOF 文件中可以设置刷盘策略，我们当时设置的就是每秒批量写入一次命令</p>\n<p><strong>面试官</strong>：Redis 的数据过期策略有哪些？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯～，在 redis 中提供了两种数据过期删除策略</p>\n<p>第一种是惰性删除，在设置该 key 过期时间后，我们不去管它，当需要该 key 时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该 key。</p>\n<p>第二种是 定期删除，就是说每隔一段时间，我们就对一些 key 进行检查，删除里面过期的 key</p>\n<p>定期清理的两种模式：</p>\n<ul>\n<li>SLOW 模式是定时任务，执行频率默认为 10hz，每次不超过 25ms，以通过修改配置文件 redis.conf 的 <strong>hz</strong> 选项来调整这个次数</li>\n<li>FAST 模式执行频率不固定，每次事件循环会尝试执行，但两次间隔不低于 2ms，每次耗时不超过 1ms</li>\n</ul>\n<p>Redis 的过期删除策略：<strong>惰性删除 + 定期删除</strong>两种策略进行配合使用。</p>\n<p><strong>面试官</strong>：Redis 的数据淘汰策略有哪些？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯，这个在 redis 中提供了很多种，默认是 noeviction，不删除任何数据，内部不足直接报错</p>\n<p>是可以在 redis 的配置文件中进行设置的，里面有两个非常重要的概念，一个是 LRU，另外一个是 LFU</p>\n<p>LRU 的意思就是最少最近使用，用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。</p>\n<p>LFU 的意思是最少频率使用。会统计每个 key 的访问频率，值越小淘汰优先级越高</p>\n<p>我们在项目设置的 allkeys-lru，挑选最近最少使用的数据淘汰，把一些经常访问的 key 留在 redis 中</p>\n<p><strong>面试官</strong>：数据库有 1000 万数据，Redis 只能缓存 20w 数据，如何保证 Redis 中的数据都是热点数据？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯，我想一下～～</p>\n<p>可以使用 allkeys-lru （挑选最近最少使用的数据淘汰）淘汰策略，那留下来的都是经常访问的热点数据</p>\n<p><strong>面试官</strong>：Redis 的内存用完了会发生什么？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯～，这个要看 redis 的数据淘汰策略是什么，如果是默认的配置，redis 内存用完以后则直接报错。我们当时设置的 allkeys-lru 策略。把最近最常访问的数据留在缓存中。</p>\n<p><strong>面试官</strong>：Redis 分布式锁如何实现？</p>\n<p><strong>候选人</strong>：嗯，在 redis 中提供了一个命令 setnx (SET if not exists)</p>\n<p>由于 redis 的单线程的，用了命令之后，只能有一个客户端对某一个 key 设置值，在没有过期或删除 key 的时候是其他客户端是不能设置这个 key 的</p>\n<p><strong>面试官</strong>：好的，那你如何控制 Redis 实现分布式锁有效时长呢？</p>\n<p><strong>候选人</strong>：嗯，的确，redis 的 setnx 指令不好控制这个问题，我们当时采用的 redis 的一个框架 redisson 实现的。</p>\n<p>在 redisson 中需要手动加锁，并且可以控制锁的失效时间和等待时间，当锁住的一个业务还没有执行完成的时候，在 redisson 中引入了一个看门狗机制，就是说每隔一段时间就检查当前业务是否还持有锁，如果持有就增加加锁的持有时间，当业务执行完成之后需要使用释放锁就可以了</p>\n<p>还有一个好处就是，在高并发下，一个业务有可能会执行很快，先客户 1 持有锁的时候，客户 2 来了以后并不会马上拒绝，它会自旋不断尝试获取锁，如果客户 1 释放之后，客户 2 就可以马上持有锁，性能也得到了提升。</p>\n<p><strong>面试官</strong>：好的，redisson 实现的分布式锁是可重入的吗？</p>\n<p><strong>候选人</strong>：嗯，是可以重入的。这样做是为了避免死锁的产生。这个重入其实在内部就是判断是否是当前线程持有的锁，如果是当前线程持有的锁就会计数，如果释放锁就会在计算上减一。在存储数据的时候采用的 hash 结构，大 key 可以按照自己的业务进行定制，其中小 key 是当前线程的唯一标识，value 是当前线程重入的次数</p>\n<p><strong>面试官</strong>：redisson 实现的分布式锁能解决主从一致性的问题吗</p>\n<p><strong>候选人</strong>：这个是不能的，比如，当线程 1 加锁成功后，master 节点数据会异步复制到 slave 节点，此时当前持有 Redis 锁的 master 节点宕机，slave 节点被提升为新的 master 节点，假如现在来了一个线程 2，再次加锁，会在新的 master 节点上加锁成功，这个时候就会出现两个节点同时持有一把锁的问题。</p>\n<p>我们可以利用 redisson 提供的红锁来解决这个问题，它的主要作用是，不能只在一个 redis 实例上创建锁，应该是在多个 redis 实例上创建锁，并且要求在大多数 redis 节点上都成功创建锁，红锁中要求是 redis 的节点数量要过半。这样就能避免线程 1 加锁成功后 master 节点宕机导致线程 2 成功加锁到新的 master 节点上的问题了。</p>\n<p>但是，如果使用了红锁，因为需要同时在多个节点上都添加锁，性能就变的很低了，并且运维维护成本也非常高，所以，我们一般在项目中也不会直接使用红锁，并且官方也暂时废弃了这个红锁</p>\n<p><strong>面试官</strong>：好的，如果业务非要保证数据的强一致性，这个该怎么解决呢？</p>\n<p>** 候选人：** 嗯～，redis 本身就是支持高可用的，做到强一致性，就非常影响性能，所以，如果有强一致性要求高的业务，建议使用 zookeeper 实现的分布式锁，它是可以保证强一致性的。</p>\n<p><strong>面试官</strong>：Redis 集群有哪些方案，知道嘛？</p>\n<p><strong>候选人</strong>：嗯～～，在 Redis 中提供的集群方案总共有三种：主从复制、哨兵模式、Redis 分片集群</p>\n<p><strong>面试官</strong>：那你来介绍一下主从同步</p>\n<p><strong>候选人</strong>：嗯，是这样的，单节点 Redis 的并发能力是有上限的，要进一步提高 Redis 的并发能力，可以搭建主从集群，实现读写分离。一般都是一主多从，主节点负责写数据，从节点负责读数据，主节点写入数据之后，需要把数据同步到从节点中</p>\n<p><strong>面试官</strong>：能说一下，主从同步数据的流程</p>\n<p><strong>候选人</strong>：嗯～～，好！主从同步分为了两个阶段，一个是全量同步，一个是增量同步</p>\n<p>全量同步是指从节点第一次与主节点建立连接的时候使用全量同步，流程是这样的：</p>\n<p>第一：从节点请求主节点同步数据，其中从节点会携带自己的 replication id 和 offset 偏移量。</p>\n<p>第二：主节点判断是否是第一次请求，主要判断的依据就是，主节点与从节点是否是同一个 replication id，如果不是，就说明是第一次同步，那主节点就会把自己的 replication id 和 offset 发送给从节点，让从节点与主节点的信息保持一致。</p>\n<p>第三：在同时主节点会执行 bgsave，生成 rdb 文件后，发送给从节点去执行，从节点先把自己的数据清空，然后执行主节点发送过来的 rdb 文件，这样就保持了一致</p>\n<p>当然，如果在 rdb 生成执行期间，依然有请求到了主节点，而主节点会以命令的方式记录到缓冲区，缓冲区是一个日志文件，最后把这个日志文件发送给从节点，这样就能保证主节点与从节点完全一致了，后期再同步数据的时候，都是依赖于这个日志文件，这个就是全量同步</p>\n<p>增量同步指的是，当从节点服务重启之后，数据就不一致了，所以这个时候，从节点会请求主节点同步数据，主节点还是判断不是第一次请求，不是第一次就获取从节点的 offset 值，然后主节点从命令日志中获取 offset 值之后的数据，发送给从节点进行数据同步</p>\n<p><strong>面试官</strong>：怎么保证 Redis 的高并发高可用</p>\n<p><strong>候选人</strong>：首先可以搭建主从集群，再加上使用 redis 中的哨兵模式，哨兵模式可以实现主从集群的自动故障恢复，里面就包含了对主从服务的监控、自动故障恢复、通知；如果 master 故障，Sentinel 会将一个 slave 提升为 master。当故障实例恢复后也以新的 master 为主；同时 Sentinel 也充当 Redis 客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给 Redis 的客户端，所以一般项目都会采用哨兵的模式来保证 redis 的高并发高可用</p>\n<p><strong>面试官</strong>：你们使用 redis 是单点还是集群，哪种集群</p>\n<p><strong>候选人</strong>：嗯！，我们当时使用的是主从（1 主 1 从）加哨兵。一般单节点不超过 10G 内存，如果 Redis 内存不足则可以给不同服务分配独立的 Redis 主从节点。尽量不做分片集群。因为集群维护起来比较麻烦，并且集群之间的心跳检测和数据通信会消耗大量的网络带宽，也没有办法使用 lua 脚本和事务</p>\n<p><strong>面试官</strong>：redis 集群脑裂，该怎么解决呢？</p>\n<p><strong>候选人</strong>：嗯！ 这个在项目很少见，不过脑裂的问题是这样的，我们现在用的是 redis 的哨兵模式集群的</p>\n<p>有的时候由于网络等原因可能会出现脑裂的情况，就是说，由于 redis master 节点和 redis salve 节点和 sentinel 处于不同的网络分区，使得 sentinel 没有能够心跳感知到 master，所以通过选举的方式提升了一个 salve 为 master，这样就存在了两个 master，就像大脑分裂了一样，这样会导致客户端还在 old master 那里写入数据，新节点无法同步数据，当网络恢复后，sentinel 会将 old master 降为 salve，这时再从新 master 同步数据，这会导致 old master 中的大量数据丢失。</p>\n<p>关于解决的话，我记得在 redis 的配置中可以设置：第一可以设置最少的 salve 节点个数，比如设置至少要有一个从节点才能同步数据，第二个可以设置主从数据复制和同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失</p>\n<p><strong>面试官</strong>：redis 的分片集群有什么作用</p>\n<p><strong>候选人</strong>：分片集群主要解决的是，海量数据存储的问题，集群中有多个 master，每个 master 保存不同数据，并且还可以给每个 master 设置多个 slave 节点，就可以继续增大集群的高并发能力。同时每个 master 之间通过 ping 监测彼此健康状态，就类似于哨兵模式了。当客户端请求可以访问集群任意节点，最终都会被转发到正确节点</p>\n<p><strong>面试官</strong>：Redis 分片集群中数据是怎么存储和读取的？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯～，在 redis 集群中是这样的</p>\n<p>Redis 集群引入了哈希槽的概念，有 16384 个哈希槽，集群中每个主节点绑定了一定范围的哈希槽范围， key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，通过槽找到对应的节点进行存储。</p>\n<p>取值的逻辑是一样的</p>\n<p><strong>面试官</strong>：Redis 是单线程的，但是为什么还那么快？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯，这个有几个原因吧～～～</p>\n<p>1、完全基于内存的，C 语言编写</p>\n<p>2、采用单线程，避免不必要的上下文切换可竞争条件</p>\n<p>3、使用多路 I/O 复用模型，非阻塞 IO</p>\n<p>例如：bgsave 和 bgrewriteaof  都是在<strong>后台</strong>执行操作，不影响主线程的正常使用，不会产生阻塞</p>\n<p><strong>面试官</strong>：能解释一下 I/O 多路复用模型？</p>\n<p><strong>候选人</strong>：嗯～～，I/O 多路复用是指利用单个线程来同时监听多个 Socket ，并在某个 Socket 可读、可写时得到通知，从而避免无效的等待，充分利用 CPU 资源。目前的 I/O 多路复用都是采用的 epoll 模式实现，它会在通知用户进程 Socket 就绪的同时，把已就绪的 Socket 写入用户空间，不需要挨个遍历 Socket 来判断是否就绪，提升了性能。</p>\n<p>其中 Redis 的网络模型就是使用 I/O 多路复用结合事件的处理器来应对多个 Socket 请求，比如，提供了连接应答处理器、命令回复处理器，命令请求处理器；</p>\n<p>在 Redis6.0 之后，为了提升更好的性能，在命令回复处理器使用了多线程来处理回复事件，在命令请求处理器中，将命令的转换使用了多线程，增加命令转换速度，在命令执行的时候，依然是单线程</p>\n</blockquote>\n",
            "tags": [
                "redis"
            ]
        },
        {
            "id": "http://127.0.0.1/blog-mysql/MySQL%E9%9D%A2%E8%AF%95%E9%A2%98-%E5%8F%82%E8%80%83%E5%9B%9E%E7%AD%94/",
            "url": "http://127.0.0.1/blog-mysql/MySQL%E9%9D%A2%E8%AF%95%E9%A2%98-%E5%8F%82%E8%80%83%E5%9B%9E%E7%AD%94/",
            "title": "Mysql相关面试题",
            "date_published": "2023-08-05T16:00:00.000Z",
            "content_html": "<blockquote>\n<p>** 面试官：**MySQL 中，如何定位慢查询？</p>\n<p><strong>候选人：</strong></p>\n<p>嗯～，我们当时做压测的时候有的接口非常的慢，接口的响应时间超过了 2 秒以上，因为我们当时的系统部署了运维的监控系统 Skywalking ，在展示的报表中可以看到是哪一个接口比较慢，并且可以分析这个接口哪部分比较慢，这里可以看到 SQL 的具体的执行时间，所以可以定位是哪个 sql 出了问题</p>\n<p>如果，项目中没有这种运维的监控系统，其实在 MySQL 中也提供了慢日志查询的功能，可以在 MySQL 的系统配置文件中开启这个慢日志的功能，并且也可以设置 SQL 执行超过多少时间来记录到一个日志文件中，我记得上一个项目配置的是 2 秒，只要 SQL 执行的时间超过了 2 秒就会记录到日志文件中，我们就可以在日志文件找到执行比较慢的 SQL 了。</p>\n<p>** 面试官：** 那这个 SQL 语句执行很慢，如何分析呢？</p>\n<p>** 候选人：** 如果一条 sql 执行很慢的话，我们通常会使用 mysql 自动的执行计划 explain 来去查看这条 sql 的执行情况，比如在这里面可以通过 key 和 key_len 检查是否命中了索引，如果本身已经添加了索引，也可以判断索引是否有失效的情况，第二个，可以通过 type 字段查看 sql 是否有进一步的优化空间，是否存在全索引扫描或全盘扫描，第三个可以通过 extra 建议来判断，是否出现了回表的情况，如果出现了，可以尝试添加索引或修改返回字段来修复</p>\n<p>** 面试官：** 了解过索引吗？（什么是索引）</p>\n<p>** 候选人：** 嗯，索引在项目中还是比较常见的，它是帮助 MySQL 高效获取数据的数据结构，主要是用来提高数据检索的效率，降低数据库的 IO 成本，同时通过索引列对数据进行排序，降低数据排序的成本，也能降低了 CPU 的消耗</p>\n<p>** 面试官：** 索引的底层数据结构了解过嘛？</p>\n<p>** 候选人：**MySQL 的默认的存储引擎 InnoDB 采用的 B + 树的数据结构来存储索引，选择 B + 树的主要的原因是：第一阶数更多，路径更短，第二个磁盘读写代价 B + 树更低，非叶子节点只存储指针，叶子阶段存储数据，第三是 B + 树便于扫库和区间查询，叶子节点是一个双向链表</p>\n<p>** 面试官：**B 树和 B + 树的区别是什么呢？</p>\n<p><strong>候选人</strong>：第一：在 B 树中，非叶子节点和叶子节点都会存放数据，而 B + 树的所有的数据都会出现在叶子节点，在查询的时候，B + 树查找效率更加稳定</p>\n<p>第二：在进行范围查询的时候，B + 树效率更高，因为 B + 树都在叶子节点存储，并且叶子节点是一个双向链表</p>\n<p>** 面试官：** 什么是聚簇索引什么是非聚簇索引？</p>\n<p><strong>候选人：</strong></p>\n<p>好的～，聚簇索引主要是指数据与索引放到一块，B + 树的叶子节点保存了整行数据，有且只有一个，一般情况下主键在作为聚簇索引的</p>\n<p>非聚簇索引值的是数据与索引分开存储，B + 树的叶子节点保存对应的主键，可以有多个，一般我们自己定义的索引都是非聚簇索引</p>\n<p>** 面试官：** 知道什么是回表查询嘛？</p>\n<p>** 候选人：** 嗯，其实跟刚才介绍的聚簇索引和非聚簇索引是有关系的，回表的意思就是通过二级索引找到对应的主键值，然后再通过主键值找到聚集索引中所对应的整行数据，这个过程就是回表</p>\n<p>【<strong>备注</strong>：如果面试官直接问回表，则需要先介绍聚簇索引和非聚簇索引】</p>\n<p>** 面试官：** 知道什么叫覆盖索引嘛？</p>\n<p>** 候选人：** 嗯～，清楚的</p>\n<p>覆盖索引是指 select 查询语句使用了索引，在返回的列，必须在索引中全部能够找到，如果我们使用 id 查询，它会直接走聚集索引查询，一次索引扫描，直接返回数据，性能高。</p>\n<p>如果按照二级索引查询数据的时候，返回的列中没有创建索引，有可能会触发回表查询，尽量避免使用 select *，尽量在返回的列中都包含添加索引的字段</p>\n<p>** 面试官：**MYSQL 超大分页怎么处理？</p>\n<p>** 候选人：** 嗯，超大分页一般都是在数据量比较大时，我们使用了 limit 分页查询，并且需要对数据进行排序，这个时候效率就很低，我们可以采用覆盖索引和子查询来解决</p>\n<p>先分页查询数据的 id 字段，确定了 id 之后，再用子查询来过滤，只查询这个 id 列表中的数据就可以了</p>\n<p>因为查询 id 的时候，走的覆盖索引，所以效率可以提升很多</p>\n<p>** 面试官：** 索引创建原则有哪些？</p>\n<p>** 候选人：** 嗯，这个情况有很多，不过都有一个大前提，就是表中的数据要超过 10 万以上，我们才会创建索引，并且添加索引的字段是查询比较频繁的字段，一般也是像作为查询条件，排序字段或分组的字段这些。</p>\n<p>还有就是，我们通常创建索引的时候都是使用复合索引来创建，一条 sql 的返回值，尽量使用覆盖索引，如果字段的区分度不高的话，我们也会把它放在组合索引后面的字段。</p>\n<p>如果某一个字段的内容较长，我们会考虑使用前缀索引来使用，当然并不是所有的字段都要添加索引，这个索引的数量也要控制，因为添加索引也会导致新增改的速度变慢。</p>\n<p>** 面试官：** 什么情况下索引会失效？</p>\n<p>** 候选人：** 嗯，这个情况比较多，我说一些自己的经验，以前遇到过的</p>\n<p>比如，索引在使用的时候没有遵循最左匹配法则，第二个是，模糊查询，如果 % 号在前面也会导致索引失效。如果在添加索引的字段上进行了运算操作或者类型转换也都会导致索引失效。</p>\n<p>我们之前还遇到过一个就是，如果使用了复合索引，中间使用了范围查询，右边的条件索引也会失效</p>\n<p>所以，通常情况下，想要判断出这条 sql 是否有索引失效的情况，可以使用 explain 执行计划来分析</p>\n<p>** 面试官：**sql 的优化的经验</p>\n<p>** 候选人：** 嗯，这个在项目还是挺常见的，当然如果直说 sql 优化的话，我们会从这几方面考虑，比如</p>\n<p>建表的时候、使用索引、sql 语句的编写、主从复制，读写分离，还有一个是如果量比较大的话，可以考虑分库分表</p>\n<p>** 面试官：** 创建表的时候，你们是如何优化的呢？</p>\n<p>** 候选人：** 这个我们主要参考的阿里出的那个开发手册《嵩山版》，就比如，在定义字段的时候需要结合字段的内容来选择合适的类型，如果是数值的话，像 tinyint、int 、bigint 这些类型，要根据实际情况选择。如果是字符串类型，也是结合存储的内容来选择 char 和 varchar 或者 text 类型</p>\n<p>** 面试官：** 那在使用索引的时候，是如何优化呢？</p>\n<p><strong>候选人：</strong>【参考索引创建原则    进行描述】</p>\n<p>** 面试官：** 你平时对 sql 语句做了哪些优化呢？</p>\n<p>** 候选人：** 嗯，这个也有很多，比如 SELECT 语句务必指明字段名称，不要直接使用 select * ，还有就是要注意 SQL 语句避免造成索引失效的写法；如果是聚合查询，尽量用 union all 代替 union ，union 会多一次过滤，效率比较低；如果是表关联的话，尽量使用 innerjoin ，不要使用用 left join right join，如必须使用 一定要以小表为驱动</p>\n<p>** 面试官：** 事务的特性是什么？可以详细说一下吗？</p>\n<p>** 候选人：** 嗯，这个比较清楚，ACID，分别指的是：原子性、一致性、隔离性、持久性；我举个例子：</p>\n<p>A 向 B 转账 500，转账成功，A 扣除 500 元，B 增加 500 元，原子操作体现在要么都成功，要么都失败</p>\n<p>在转账的过程中，数据要一致，A 扣除了 500，B 必须增加 500</p>\n<p>在转账的过程中，隔离性体现在 A 像 B 转账，不能受其他事务干扰</p>\n<p>在转账的过程中，持久性体现在事务提交后，要把数据持久化（可以说是落盘操作）</p>\n<p><strong>面试官</strong>：并发事务带来哪些问题？</p>\n<p><strong>候选人</strong>：</p>\n<p>我们在项目开发中，多个事务并发进行是经常发生的，并发也是必然的，有可能导致一些问题</p>\n<p>第一是脏读， 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是 “脏数据”，依据 “脏数据” 所做的操作可能是不正确的。</p>\n<p>第二是不可重复读：比如在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。</p>\n<p>第三是幻读（Phantom read）：幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。</p>\n<p><strong>面试官</strong>：怎么解决这些问题呢？MySQL 的默认隔离级别是？</p>\n<p><strong>候选人</strong>：解决方案是对事务进行隔离</p>\n<p>MySQL 支持四种隔离级别，分别有：</p>\n<p>第一个是，未提交读（read uncommitted）它解决不了刚才提出的所有问题，一般项目中也不用这个。第二个是读已提交（read committed）它能解决脏读的问题的，但是解决不了不可重复读和幻读。第三个是可重复读（repeatable read）它能解决脏读和不可重复读，但是解决不了幻读，这个也是 mysql 默认的隔离级别。第四个是串行化（serializable）它可以解决刚才提出来的所有问题，但是由于让是事务串行执行的，性能比较低。所以，我们一般使用的都是 mysql 默认的隔离级别：可重复读</p>\n<p><strong>面试官</strong>：undo log 和 redo log 的区别</p>\n<p><strong>候选人</strong>：好的，其中 redo log 日志记录的是数据页的物理变化，服务宕机可用来同步数据，而 undo log 不同，它主要记录的是逻辑日志，当事务回滚时，通过逆操作恢复原来的数据，比如我们删除一条数据的时候，就会在 undo log 日志文件中新增一条 delete 语句，如果发生回滚就执行逆操作；</p>\n<p>redo log 保证了事务的持久性，undo log 保证了事务的原子性和一致性</p>\n<p><strong>面试官</strong>：事务中的隔离性是如何保证的呢？(你解释一下 MVCC)</p>\n<p><strong>候选人</strong>：事务的隔离性是由锁和 mvcc 实现的。</p>\n<p>其中 mvcc 的意思是多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，它的底层实现主要是分为了三个部分，第一个是隐藏字段，第二个是 undo log 日志，第三个是 readView 读视图</p>\n<p>隐藏字段是指：在 mysql 中给每个表都设置了隐藏字段，有一个是 trx_id (事务 id)，记录每一次操作的事务 id，是自增的；另一个字段是 roll_pointer (回滚指针)，指向上一个版本的事务版本记录地址</p>\n<p>undo log 主要的作用是记录回滚日志，存储老版本数据，在内部会形成一个版本链，在多个事务并行操作某一行记录，记录不同事务修改数据的版本，通过 roll_pointer 指针形成一个链表</p>\n<p>readView 解决的是一个事务查询选择版本的问题，在内部定义了一些匹配规则和当前的一些事务 id 判断该访问那个版本的数据，不同的隔离级别快照读是不一样的，最终的访问的结果不一样。如果是 rc 隔离级别，每一次执行快照读时生成 ReadView，如果是 rr 隔离级别仅在事务中第一次执行快照读时生成 ReadView，后续复用</p>\n<p><strong>面试官</strong>：MySQL 主从同步原理</p>\n<p><strong>候选人</strong>：MySQL 主从复制的核心就是二进制日志 (DDL（数据定义语言）语句和 DML（数据操纵语言）语句)，它的步骤是这样的：</p>\n<p>第一：主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。</p>\n<p>第二：从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。</p>\n<p>第三：从库重做中继日志中的事件，将改变反映它自己的数据</p>\n<p><strong>面试官</strong>：你们项目用过 MySQL 的分库分表吗？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯，因为我们都是微服务开发，每个微服务对应了一个数据库，是根据业务进行拆分的，这个其实就是垂直拆分。</p>\n<p><strong>面试官</strong>：那你之前使用过水平分库吗？</p>\n<p><strong>候选人</strong>：</p>\n<p>嗯，这个是使用过的，我们当时的业务是 (xxx)，一开始，我们也是单库，后来这个业务逐渐发展，业务量上来的很迅速，其中 (xx) 表已经存放了超过 1000 万的数据，我们做了很多优化也不好使，性能依然很慢，所以当时就使用了水平分库。</p>\n<p>我们一开始先做了 3 台服务器对应了 3 个数据库，由于库多了，需要分片，我们当时采用的 mycat 来作为数据库的中间件。数据都是按照 id（自增）取模的方式来存取的。</p>\n<p>当然一开始的时候，那些旧数据，我们做了一些清洗的工作，我们也是按照 id 取模规则分别存储到了各个数据库中，好处就是可以让各个数据库分摊存储和读取的压力，解决了我们当时性能的问题</p>\n</blockquote>\n",
            "tags": [
                "redis"
            ]
        },
        {
            "id": "http://127.0.0.1/hello-world/",
            "url": "http://127.0.0.1/hello-world/",
            "title": "Hello World",
            "date_published": "2023-08-05T07:55:28.888Z",
            "content_html": "<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n",
            "tags": []
        }
    ]
}